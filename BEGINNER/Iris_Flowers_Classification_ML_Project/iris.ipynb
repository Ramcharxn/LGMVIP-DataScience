{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iris Flowers Classification ML Project :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length in cm</th>\n",
       "      <th>sepal width in cm</th>\n",
       "      <th>petal length in cm</th>\n",
       "      <th>petal width in cm</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length in cm  sepal width in cm  petal length in cm  \\\n",
       "0                 4.9                3.0                 1.4   \n",
       "1                 4.7                3.2                 1.3   \n",
       "2                 4.6                3.1                 1.5   \n",
       "3                 5.0                3.6                 1.4   \n",
       "4                 5.4                3.9                 1.7   \n",
       "\n",
       "   petal width in cm        class  \n",
       "0                0.2  Iris-setosa  \n",
       "1                0.2  Iris-setosa  \n",
       "2                0.2  Iris-setosa  \n",
       "3                0.2  Iris-setosa  \n",
       "4                0.4  Iris-setosa  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = ['sepal length in cm','sepal width in cm','petal length in cm','petal width in cm','class']\n",
    "df = pd.read_csv('irisdata.csv')\n",
    "df.columns = columns\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "df = shuffle(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 2, 0, 0, 1, 1, 2, 2, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 2,\n",
       "       1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 2, 2,\n",
       "       2, 0, 0, 0, 2, 2, 1, 1, 2, 2, 0, 2, 1, 2, 2, 1, 1, 0, 0, 2, 2, 1,\n",
       "       2, 2, 2, 2, 1, 2, 2, 2, 2, 0, 1, 1, 2, 0, 0, 0, 1, 1, 2, 1, 2, 2,\n",
       "       1, 0, 2, 0, 2, 1, 1, 0, 2, 0, 1, 0, 0, 0, 2, 2, 0, 0, 0, 2, 1, 2,\n",
       "       2, 0, 0, 0, 1, 0, 2, 2, 0, 1, 1, 0, 1, 2, 1, 0, 1, 1, 0, 2, 0, 1,\n",
       "       2, 2, 2, 0, 1, 2, 0, 2, 0, 2, 2, 0, 2, 2, 1, 2, 0])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(df['class'])\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.38888889, 0.375     , 0.54237288, 0.5       ],\n",
       "       [0.47222222, 0.375     , 0.59322034, 0.58333333],\n",
       "       [0.25      , 0.29166667, 0.49152542, 0.54166667],\n",
       "       [0.30555556, 0.58333333, 0.08474576, 0.125     ],\n",
       "       [0.72222222, 0.5       , 0.79661017, 0.91666667],\n",
       "       [0.19444444, 0.66666667, 0.06779661, 0.04166667],\n",
       "       [0.22222222, 0.54166667, 0.11864407, 0.16666667],\n",
       "       [0.72222222, 0.45833333, 0.66101695, 0.58333333],\n",
       "       [0.38888889, 0.41666667, 0.54237288, 0.45833333],\n",
       "       [0.94444444, 0.41666667, 0.86440678, 0.91666667],\n",
       "       [0.55555556, 0.33333333, 0.69491525, 0.58333333],\n",
       "       [0.33333333, 0.16666667, 0.45762712, 0.375     ],\n",
       "       [0.08333333, 0.5       , 0.06779661, 0.04166667],\n",
       "       [0.19444444, 0.5       , 0.03389831, 0.04166667],\n",
       "       [0.52777778, 0.375     , 0.55932203, 0.5       ],\n",
       "       [0.05555556, 0.125     , 0.05084746, 0.08333333],\n",
       "       [0.36111111, 0.375     , 0.44067797, 0.5       ],\n",
       "       [0.52777778, 0.08333333, 0.59322034, 0.58333333],\n",
       "       [0.27777778, 0.70833333, 0.08474576, 0.04166667],\n",
       "       [0.33333333, 0.125     , 0.50847458, 0.5       ],\n",
       "       [0.41666667, 0.25      , 0.50847458, 0.45833333],\n",
       "       [0.41666667, 0.29166667, 0.69491525, 0.75      ],\n",
       "       [0.33333333, 0.16666667, 0.47457627, 0.41666667],\n",
       "       [0.41666667, 0.29166667, 0.49152542, 0.45833333],\n",
       "       [0.58333333, 0.5       , 0.59322034, 0.58333333],\n",
       "       [0.13888889, 0.41666667, 0.06779661, 0.        ],\n",
       "       [0.36111111, 0.41666667, 0.59322034, 0.58333333],\n",
       "       [0.13888889, 0.58333333, 0.10169492, 0.04166667],\n",
       "       [0.47222222, 0.29166667, 0.69491525, 0.625     ],\n",
       "       [0.63888889, 0.375     , 0.61016949, 0.5       ],\n",
       "       [0.38888889, 1.        , 0.08474576, 0.125     ],\n",
       "       [0.13888889, 0.41666667, 0.06779661, 0.08333333],\n",
       "       [0.66666667, 0.45833333, 0.62711864, 0.58333333],\n",
       "       [0.08333333, 0.66666667, 0.        , 0.04166667],\n",
       "       [0.5       , 0.375     , 0.62711864, 0.54166667],\n",
       "       [0.19444444, 0.41666667, 0.10169492, 0.04166667],\n",
       "       [0.75      , 0.5       , 0.62711864, 0.54166667],\n",
       "       [0.5       , 0.33333333, 0.62711864, 0.45833333],\n",
       "       [0.22222222, 0.75      , 0.08474576, 0.08333333],\n",
       "       [0.44444444, 0.5       , 0.6440678 , 0.70833333],\n",
       "       [0.19444444, 0.54166667, 0.06779661, 0.04166667],\n",
       "       [0.58333333, 0.375     , 0.55932203, 0.5       ],\n",
       "       [1.        , 0.75      , 0.91525424, 0.79166667],\n",
       "       [0.55555556, 0.54166667, 0.84745763, 1.        ],\n",
       "       [0.36111111, 0.33333333, 0.66101695, 0.79166667],\n",
       "       [0.11111111, 0.5       , 0.10169492, 0.04166667],\n",
       "       [0.16666667, 0.45833333, 0.08474576, 0.        ],\n",
       "       [0.25      , 0.58333333, 0.06779661, 0.04166667],\n",
       "       [0.61111111, 0.41666667, 0.71186441, 0.79166667],\n",
       "       [0.41666667, 0.33333333, 0.69491525, 0.95833333],\n",
       "       [0.19444444, 0.125     , 0.38983051, 0.375     ],\n",
       "       [0.55555556, 0.125     , 0.57627119, 0.5       ],\n",
       "       [0.77777778, 0.41666667, 0.83050847, 0.83333333],\n",
       "       [0.83333333, 0.375     , 0.89830508, 0.70833333],\n",
       "       [0.22222222, 0.58333333, 0.08474576, 0.04166667],\n",
       "       [0.66666667, 0.41666667, 0.71186441, 0.91666667],\n",
       "       [0.16666667, 0.16666667, 0.38983051, 0.375     ],\n",
       "       [0.47222222, 0.08333333, 0.6779661 , 0.58333333],\n",
       "       [0.91666667, 0.41666667, 0.94915254, 0.83333333],\n",
       "       [0.5       , 0.33333333, 0.50847458, 0.5       ],\n",
       "       [0.33333333, 0.25      , 0.57627119, 0.45833333],\n",
       "       [0.25      , 0.625     , 0.08474576, 0.04166667],\n",
       "       [0.        , 0.41666667, 0.01694915, 0.        ],\n",
       "       [0.69444444, 0.5       , 0.83050847, 0.91666667],\n",
       "       [0.61111111, 0.41666667, 0.81355932, 0.875     ],\n",
       "       [0.36111111, 0.29166667, 0.54237288, 0.5       ],\n",
       "       [0.16666667, 0.20833333, 0.59322034, 0.66666667],\n",
       "       [0.5       , 0.25      , 0.77966102, 0.54166667],\n",
       "       [0.5       , 0.41666667, 0.66101695, 0.70833333],\n",
       "       [0.55555556, 0.375     , 0.77966102, 0.70833333],\n",
       "       [0.66666667, 0.41666667, 0.6779661 , 0.66666667],\n",
       "       [0.55555556, 0.29166667, 0.66101695, 0.70833333],\n",
       "       [0.80555556, 0.41666667, 0.81355932, 0.625     ],\n",
       "       [0.66666667, 0.45833333, 0.77966102, 0.95833333],\n",
       "       [0.58333333, 0.45833333, 0.76271186, 0.70833333],\n",
       "       [0.08333333, 0.45833333, 0.08474576, 0.04166667],\n",
       "       [0.38888889, 0.25      , 0.42372881, 0.375     ],\n",
       "       [0.47222222, 0.58333333, 0.59322034, 0.625     ],\n",
       "       [0.86111111, 0.33333333, 0.86440678, 0.75      ],\n",
       "       [0.19444444, 0.625     , 0.05084746, 0.08333333],\n",
       "       [0.02777778, 0.41666667, 0.05084746, 0.04166667],\n",
       "       [0.30555556, 0.79166667, 0.05084746, 0.125     ],\n",
       "       [0.55555556, 0.54166667, 0.62711864, 0.625     ],\n",
       "       [0.66666667, 0.45833333, 0.57627119, 0.54166667],\n",
       "       [0.58333333, 0.33333333, 0.77966102, 0.875     ],\n",
       "       [0.19444444, 0.        , 0.42372881, 0.375     ],\n",
       "       [0.58333333, 0.29166667, 0.72881356, 0.75      ],\n",
       "       [0.94444444, 0.25      , 1.        , 0.91666667],\n",
       "       [0.5       , 0.41666667, 0.61016949, 0.54166667],\n",
       "       [0.02777778, 0.375     , 0.06779661, 0.04166667],\n",
       "       [0.80555556, 0.5       , 0.84745763, 0.70833333],\n",
       "       [0.19444444, 0.58333333, 0.10169492, 0.125     ],\n",
       "       [0.66666667, 0.20833333, 0.81355932, 0.70833333],\n",
       "       [0.38888889, 0.33333333, 0.52542373, 0.5       ],\n",
       "       [0.69444444, 0.33333333, 0.6440678 , 0.54166667],\n",
       "       [0.30555556, 0.58333333, 0.11864407, 0.04166667],\n",
       "       [0.72222222, 0.45833333, 0.69491525, 0.91666667],\n",
       "       [0.19444444, 0.625     , 0.10169492, 0.20833333],\n",
       "       [0.22222222, 0.20833333, 0.33898305, 0.41666667],\n",
       "       [0.13888889, 0.45833333, 0.10169492, 0.04166667],\n",
       "       [0.33333333, 0.625     , 0.05084746, 0.04166667],\n",
       "       [0.33333333, 0.91666667, 0.06779661, 0.04166667],\n",
       "       [0.61111111, 0.5       , 0.69491525, 0.79166667],\n",
       "       [0.80555556, 0.66666667, 0.86440678, 1.        ],\n",
       "       [0.22222222, 0.70833333, 0.08474576, 0.125     ],\n",
       "       [0.30555556, 0.70833333, 0.08474576, 0.04166667],\n",
       "       [0.25      , 0.875     , 0.08474576, 0.        ],\n",
       "       [0.38888889, 0.20833333, 0.6779661 , 0.79166667],\n",
       "       [0.61111111, 0.33333333, 0.61016949, 0.58333333],\n",
       "       [0.66666667, 0.54166667, 0.79661017, 1.        ],\n",
       "       [0.55555556, 0.20833333, 0.6779661 , 0.75      ],\n",
       "       [0.11111111, 0.5       , 0.05084746, 0.04166667],\n",
       "       [0.38888889, 0.75      , 0.11864407, 0.08333333],\n",
       "       [0.41666667, 0.83333333, 0.03389831, 0.04166667],\n",
       "       [0.41666667, 0.29166667, 0.52542373, 0.375     ],\n",
       "       [0.16666667, 0.45833333, 0.08474576, 0.        ],\n",
       "       [0.41666667, 0.29166667, 0.69491525, 0.75      ],\n",
       "       [0.55555556, 0.58333333, 0.77966102, 0.95833333],\n",
       "       [0.30555556, 0.79166667, 0.11864407, 0.125     ],\n",
       "       [0.47222222, 0.08333333, 0.50847458, 0.375     ],\n",
       "       [0.44444444, 0.41666667, 0.54237288, 0.58333333],\n",
       "       [0.16666667, 0.45833333, 0.08474576, 0.        ],\n",
       "       [0.55555556, 0.20833333, 0.66101695, 0.58333333],\n",
       "       [0.52777778, 0.58333333, 0.74576271, 0.91666667],\n",
       "       [0.36111111, 0.41666667, 0.52542373, 0.5       ],\n",
       "       [0.16666667, 0.41666667, 0.06779661, 0.04166667],\n",
       "       [0.36111111, 0.20833333, 0.49152542, 0.41666667],\n",
       "       [0.30555556, 0.41666667, 0.59322034, 0.58333333],\n",
       "       [0.02777778, 0.5       , 0.05084746, 0.04166667],\n",
       "       [0.58333333, 0.33333333, 0.77966102, 0.83333333],\n",
       "       [0.22222222, 0.75      , 0.10169492, 0.04166667],\n",
       "       [0.63888889, 0.41666667, 0.57627119, 0.54166667],\n",
       "       [0.69444444, 0.41666667, 0.76271186, 0.83333333],\n",
       "       [0.44444444, 0.41666667, 0.69491525, 0.70833333],\n",
       "       [0.52777778, 0.33333333, 0.6440678 , 0.70833333],\n",
       "       [0.19444444, 0.58333333, 0.08474576, 0.04166667],\n",
       "       [0.38888889, 0.33333333, 0.59322034, 0.5       ],\n",
       "       [0.94444444, 0.75      , 0.96610169, 0.875     ],\n",
       "       [0.13888889, 0.58333333, 0.15254237, 0.04166667],\n",
       "       [0.47222222, 0.41666667, 0.6440678 , 0.70833333],\n",
       "       [0.08333333, 0.58333333, 0.06779661, 0.08333333],\n",
       "       [0.61111111, 0.41666667, 0.76271186, 0.70833333],\n",
       "       [0.72222222, 0.45833333, 0.74576271, 0.83333333],\n",
       "       [0.22222222, 0.75      , 0.15254237, 0.125     ],\n",
       "       [0.94444444, 0.33333333, 0.96610169, 0.79166667],\n",
       "       [0.66666667, 0.54166667, 0.79661017, 0.83333333],\n",
       "       [0.33333333, 0.20833333, 0.50847458, 0.5       ],\n",
       "       [0.58333333, 0.5       , 0.72881356, 0.91666667],\n",
       "       [0.22222222, 0.625     , 0.06779661, 0.08333333]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(df.drop('class',axis=1))\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Building and Fine tunning the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {\n",
    "    'logistic_reg':{\n",
    "        'model': LogisticRegression(solver='liblinear'),\n",
    "        'params':{\n",
    "            'penalty':['l1','l2'],\n",
    "            'C':[0.5, 1, 10]\n",
    "        }\n",
    "    },\n",
    "    'svc': {\n",
    "        'model': SVC(),\n",
    "        'params': {\n",
    "            'C':[0.5, 1, 10],\n",
    "            'kernel':['rbf','poly']\n",
    "        }\n",
    "    },\n",
    "    'knn':{\n",
    "        'model':KNeighborsClassifier(),\n",
    "        'params':{\n",
    "            'weights':['uniform','distance'],\n",
    "            'n_neighbors':[3, 5, 7]\n",
    "        }\n",
    "    },\n",
    "    'random_forest':{\n",
    "        'model': RandomForestClassifier(),\n",
    "        'params':{\n",
    "            'n_estimators':[5, 50, 100],\n",
    "            'criterion':['gini','entropy']\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>best_score</th>\n",
       "      <th>best_params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>logistic_reg</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>{'C': 10, 'penalty': 'l1'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>svc</td>\n",
       "      <td>0.970370</td>\n",
       "      <td>{'C': 0.5, 'kernel': 'poly'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>knn</td>\n",
       "      <td>0.970370</td>\n",
       "      <td>{'n_neighbors': 5, 'weights': 'uniform'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>0.977778</td>\n",
       "      <td>{'criterion': 'gini', 'n_estimators': 5}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           model  best_score                               best_params\n",
       "0   logistic_reg    0.933333                {'C': 10, 'penalty': 'l1'}\n",
       "1            svc    0.970370              {'C': 0.5, 'kernel': 'poly'}\n",
       "2            knn    0.970370  {'n_neighbors': 5, 'weights': 'uniform'}\n",
       "3  random_forest    0.977778  {'criterion': 'gini', 'n_estimators': 5}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = []\n",
    "\n",
    "for model_name, mp in model_params.items():\n",
    "    clf =  GridSearchCV(mp['model'], mp['params'], cv=5, return_train_score=False)\n",
    "    clf.fit(X_train, y_train)\n",
    "    scores.append({\n",
    "        'model': model_name,\n",
    "        'best_score': clf.best_score_,\n",
    "        'best_params': clf.best_params_\n",
    "    })\n",
    "    \n",
    "df = pd.DataFrame(scores,columns=['model','best_score','best_params'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 2, 1, 0, 2, 0, 2, 1, 0, 1, 2, 0, 2])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors= 3, weights= 'uniform')\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ploting the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5, 0, 0],\n",
       "       [0, 4, 0],\n",
       "       [0, 0, 6]], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(24.0, 0.5, 'Truth')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 360x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "\n",
    "plt.figure(figsize=(5,4))\n",
    "sn.heatmap(cm, annot=True)\n",
    "\n",
    "plt.xlabel('Predict')\n",
    "plt.ylabel('Truth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c79ead59f29e134e998346a450e0935a86ce2821ab5ea091c75cc2566743050b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
